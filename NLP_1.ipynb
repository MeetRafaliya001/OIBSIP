{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtMNgYPZhiAUtX3ils5Auw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeetRafaliya001/OIBSIP/blob/main/NLP_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqnPTClzU30t"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoMCrWU0U87r",
        "outputId": "e59d83f0-a818-4aba-c399-abd5700dcfcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import sent_tokenize"
      ],
      "metadata": {
        "id": "577tMVDkVE1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Good Morning all. My Name is Meet Rafaliya\""
      ],
      "metadata": {
        "id": "YKHkpl9QVKCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = sent_tokenize(text)"
      ],
      "metadata": {
        "id": "WbR1GQBmVSaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t6HWSTIVaCj",
        "outputId": "e60b273d-8d84-4eec-dce7-39f7a2b2db84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good Morning all.', 'My Name is Meet Rafaliya']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentence_tokens:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGIyMBu5Vfs-",
        "outputId": "7cfa163b-71ea-4605-f7d6-784106249158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good Morning all.\n",
            "My Name is Meet Rafaliya\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word tokenization"
      ],
      "metadata": {
        "id": "e09l3Mx_Vs7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "x1ouRjcyVwQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Hello Everyone! How are you?\""
      ],
      "metadata": {
        "id": "3Iji-J_eV2Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = word_tokenize(sentence)\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K0HIHOuV_W0",
        "outputId": "8a68c0e9-36d1-4278-cc89-9634ff8c50ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Everyone', '!', 'How', 'are', 'you', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer, WordPunctTokenizer, WhitespaceTokenizer\n",
        "tree_tokenizer = TreebankWordTokenizer ()\n",
        "word_punct_tokenizer = WordPunctTokenizer ()\n",
        "white_space_tokenizer = WhitespaceTokenizer ()"
      ],
      "metadata": {
        "id": "SeKmbIFrWcVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = tree_tokenizer.tokenize (sentence)\n",
        "print (word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xe-4ve6XQsz",
        "outputId": "86bef794-d77e-402b-9d0b-b36e9355241d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Everyone', '!', 'How', 'are', 'you', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = white_space_tokenizer.tokenize(sentence)\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atCIaK9SXZ8i",
        "outputId": "e0cac701-65c9-4b6a-ba5c-3bd8c55059c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Everyone!', 'How', 'are', 'you?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming"
      ],
      "metadata": {
        "id": "GrocFXGPXuPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, LancasterStemmer"
      ],
      "metadata": {
        "id": "J4v_PNz2Xv8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "print (porter_stemmer.stem('observing'))\n",
        "print (porter_stemmer.stem('observs'))\n",
        "print (porter_stemmer.stem('observe'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyhPleHqYFzi",
        "outputId": "9c9b3b4f-064f-4ae1-e6be-71f1c0ebf74a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observ\n",
            "observ\n",
            "observ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lancaster_stemmer = LancasterStemmer()\n",
        "print (lancaster_stemmer.stem('observing'))\n",
        "print (lancaster_stemmer.stem('observs'))\n",
        "print (lancaster_stemmer.stem('observe'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boer4yiEYREZ",
        "outputId": "d733e36e-862f-444c-e230-a6103458f8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observ\n",
            "observ\n",
            "observ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "Pocd-0jAZC2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "gQKTHeb_ZGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tay-d_sfZb_O",
        "outputId": "c287e88a-e118-4a3d-bf7d-cda0af6c5f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "print (lemmatizer.lemmatize (\"running\"))\n",
        "print (lemmatizer.lemmatize (\"runs\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX2EwzsNZg_l",
        "outputId": "a8e9a63f-4474-481e-d2a6-87d4f50bc4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running\n",
            "run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatizer- Returns verb, noun, Adverb, Adjective form"
      ],
      "metadata": {
        "id": "psX7kFdZZtse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(word):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    print(\"verb form: \"+ lemmatizer.lemmatize (word, pos=\"v\"))\n",
        "    print (\"noun form: \" + lemmatizer.lemmatize (word, pos=\"n\"))\n",
        "    print(\"adverb form: \" + lemmatizer.lemmatize (word, pos=\"r\"))\n",
        "    print(\"adjective form: \" + lemmatizer.lemmatize (word, pos=\"a\"))"
      ],
      "metadata": {
        "id": "ATn1aE9wZuq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize(\"ears\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzBxiPSUaqVe",
        "outputId": "f189a8b3-7583-4c26-bbd8-629a7765aaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verb form: ears\n",
            "noun form: ear\n",
            "adverb form: ears\n",
            "adjective form: ears\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize(\"running\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4moYm05AawmS",
        "outputId": "1f425b47-64ff-4f75-e05b-15a718c26209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "verb form: run\n",
            "noun form: running\n",
            "adverb form: running\n",
            "adjective form: running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet shows the comparison between stemming and lemmatization."
      ],
      "metadata": {
        "id": "THtkAo0ObA1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "1QMfF9NUbCiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer();\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "RuPmrAnZbJxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem(\"deactivating\"))\n",
        "print(stemmer.stem(\"deactivated\"))\n",
        "print(stemmer.stem(\"deactivates\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK1x5T4zbQs5",
        "outputId": "27f52ef8-640d-4a71-d22e-45c4260fa9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deactiv\n",
            "deactiv\n",
            "deactiv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (lemmatizer.lemmatize (\"deactivating\", pos=\"v\"))\n",
        "print (lemmatizer.lemmatize (\"deactivating\", pos=\"r\"))\n",
        "print (lemmatizer.lemmatize(\"deactivating\", pos=\"n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr1a4RTabinA",
        "outputId": "f4f850b6-86f2-4210-f05a-6c4c2f9ad339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deactivate\n",
            "deactivating\n",
            "deactivating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stemmer.stem('stones'))\n",
        "print (stemmer.stem('speaking'))\n",
        "print (stemmer.stem('bedroom'))\n",
        "print (stemmer.stem('jokes'))\n",
        "print (stemmer.stem('lisa'))\n",
        "print(stemmer.stem('purple'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjeqKcj_bsTN",
        "outputId": "9e9b0a05-b9c9-4455-c0a1-3595c652b08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stone\n",
            "speak\n",
            "bedroom\n",
            "joke\n",
            "lisa\n",
            "purpl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (lemmatizer.lemmatize('speaking'))\n",
        "print (lemmatizer.lemmatize('bedroom'))\n",
        "print (lemmatizer.lemmatize('jokes'))\n",
        "print (lemmatizer.lemmatize('lisa'))\n",
        "print(lemmatizer.lemmatize('purple'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xQvj5UBcIUO",
        "outputId": "88f07abe-2791-456d-b137-234f792511ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speaking\n",
            "bedroom\n",
            "joke\n",
            "lisa\n",
            "purple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part of speech (POS) tagging"
      ],
      "metadata": {
        "id": "-oTdnhnNcahG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag, download\n",
        "# Download the averaged_perceptron_tagger if it's not already downloaded\n",
        "download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJqFXtsLJcw8",
        "outputId": "54073b3a-76b7-4016-eca2-3b0e1294e2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Book the ticket.\""
      ],
      "metadata": {
        "id": "AkA6wH6FJyFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = word_tokenize(sentence)\n",
        "print(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9la7_yNDLrdc",
        "outputId": "f7613254-4eb0-41c2-bc47-55a813cfbd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Book', 'the', 'ticket', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tag(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbAVNBs2L90W",
        "outputId": "03a7dc0a-a31a-4afb-c3a9-eb3188e31989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Book', 'IN'), ('the', 'DT'), ('ticket', 'NN'), ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking-making word phases"
      ],
      "metadata": {
        "id": "kRYukmAgMIRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "SpIbIV0mMOfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The clean data is important for application development.\"\n",
        "tokens = nltk.word_tokenize (text)\n",
        "print (tokens)\n",
        "tag = nltk.pos_tag(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVmaOLETMgT0",
        "outputId": "d8752dfe-2dda-4986-c1b5-a949f8cae949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'clean', 'data', 'is', 'important', 'for', 'application', 'development', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9toDo-vMvVa",
        "outputId": "4ee84f05-50a7-4d0b-f31a-e55e4a15999a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('clean', 'JJ'), ('data', 'NN'), ('is', 'VBZ'), ('important', 'JJ'), ('for', 'IN'), ('application', 'NN'), ('development', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
        "cp = nltk.RegexpParser (grammar)"
      ],
      "metadata": {
        "id": "MkCLIGbRNEKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cp.parse(tag)\n",
        "print (result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-LADE05NWV1",
        "outputId": "02f0320b-f5d1-43ec-db80-b588d9d4dc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT clean/JJ data/NN)\n",
            "  is/VBZ\n",
            "  important/JJ\n",
            "  for/IN\n",
            "  (NP application/NN)\n",
            "  (NP development/NN)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parse Tree"
      ],
      "metadata": {
        "id": "trn1rlTONfQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = cp.parse(tag)"
      ],
      "metadata": {
        "id": "MYENGW-COPnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for subtree in tree.subtrees():\n",
        "   print (subtree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIu1Hz1jOV-0",
        "outputId": "f07e1d6f-dcda-430b-8d3c-54fd40f45421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP The/DT clean/JJ data/NN)\n",
            "  is/VBZ\n",
            "  important/JJ\n",
            "  for/IN\n",
            "  (NP application/NN)\n",
            "  (NP development/NN)\n",
            "  ./.)\n",
            "(NP The/DT clean/JJ data/NN)\n",
            "(NP application/NN)\n",
            "(NP development/NN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stop word Removal"
      ],
      "metadata": {
        "id": "JQ1AfjfAOvHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UaWDQDjOwwz",
        "outputId": "7fe29d16-422b-4678-bc7c-7f0a93a1944b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB1kaGkdO6-u",
        "outputId": "454db1f5-4e71-4d97-e33b-b58d76905502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Data structure understanding is must for a computer engineer.\""
      ],
      "metadata": {
        "id": "LrPhsssCPBRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens = word_tokenize (sentence)\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGdUwGmiPbtL",
        "outputId": "6f9af749-2902-4396-986f-69f33262f03b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data', 'structure', 'understanding', 'is', 'must', 'for', 'a', 'computer', 'engineer', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_tokens = word_tokens [:]\n",
        "for token in word_tokens:\n",
        "  if token in stopwords.words('english'):\n",
        "    clean_tokens.remove(token)"
      ],
      "metadata": {
        "id": "baL6D81rPsTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clean_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueEdXVhBQGKZ",
        "outputId": "5901c93f-8432-41a5-da95-afc48626f4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Data', 'structure', 'understanding', 'must', 'computer', 'engineer', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WORDNET"
      ],
      "metadata": {
        "id": "kv8dyEHDQ5__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "d6YJAF4URASO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdB8nhVSROdL",
        "outputId": "e5685810-7685-4035-9f82-1f06c78ff3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet.synsets(\"gun\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh6nXUwiRVfe",
        "outputId": "322197d6-6b02-4b69-b50a-6843a91af1e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('gun.n.01'),\n",
              " Synset('artillery.n.01'),\n",
              " Synset('gunman.n.02'),\n",
              " Synset('gunman.n.01'),\n",
              " Synset('grease-gun.n.01'),\n",
              " Synset('accelerator.n.01'),\n",
              " Synset('gun.n.07'),\n",
              " Synset('gun.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet.synsets(\"flower\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZbNBzOIReT3",
        "outputId": "2227cfa0-1f22-40da-fdfd-e6e6f3b742e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('flower.n.01'),\n",
              " Synset('flower.n.02'),\n",
              " Synset('flower.n.03'),\n",
              " Synset('bloom.v.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn = wordnet.synset('flower.n.01')\n",
        "syn.lemma_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kXFnUiaRhNx",
        "outputId": "131f321a-af5c-45a2-fb1c-ed77551c6609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['flower']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "syn.definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HkZwH7RASAni",
        "outputId": "7a8c8be6-7273-4b6c-e13e-da9786a94add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a plant cultivated for its blooms or blossoms'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordnet.synset(\"flower.n.01\").examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs0sUEsISZaL",
        "outputId": "339442ff-cbad-42be-c2ba-961b841e0cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synonyms = []\n",
        "for syn in wordnet.synsets('long'):\n",
        "   for lemma in syn.lemmas():\n",
        "      synonyms.append(lemma.name())\n",
        "print(synonyms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlUqoDTXTcUY",
        "outputId": "8fe037b8-aaa8-4b9e-b043-36af7f959b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hanker', 'long', 'yearn', 'long', 'long', 'long', 'retentive', 'recollective', 'long', 'tenacious', 'long', 'long', 'long', 'farseeing', 'farsighted', 'foresighted', 'foresightful', 'prospicient', 'long', 'longsighted', 'long', 'long', 'long']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "antonyms = []\n",
        "for syn in wordnet.synsets(\"like\"):\n",
        "    for l in syn.lemmas():\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms() [0].name())\n",
        "print(antonyms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRecnHeFTnQh",
        "outputId": "0e4b32bc-f525-46ca-930e-8766fb63eb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dislike', 'unlike', 'unlike', 'unalike']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CfZ8BzJ3UqIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Named Entity Recognition (NER)"
      ],
      "metadata": {
        "id": "HCremkfEUqMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk"
      ],
      "metadata": {
        "id": "bbv3MdlaUrgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF_J17SLU2hY",
        "outputId": "b34f3d86-3c75-409d-aef5-61816c785f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlj5i0O9U9k9",
        "outputId": "f5bb2c22-1ed3-423e-fb3d-df1b4d366125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Johney works at Intel.\""
      ],
      "metadata": {
        "id": "huNnXYJGVWJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize (text)\n",
        "print (tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ckbGHikVcAD",
        "outputId": "aa8431c8-ea7d-4224-8b59-466e8f802b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Johney', 'works', 'at', 'Intel', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_tokens1 = pos_tag(tokens)\n",
        "print (tagged_tokens1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci5_KXD0VitE",
        "outputId": "1cc763a2-2b2b-4ed4-f859-0230f2b1a33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Johney', 'NNP'), ('works', 'VBZ'), ('at', 'IN'), ('Intel', 'NNP'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tree = ne_chunk(tagged_tokens1)"
      ],
      "metadata": {
        "id": "odVqGmisVydU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ner_tree)"
      ],
      "metadata": {
        "id": "cm7gwW0HV93u",
        "outputId": "935c237a-7b25-4036-938b-f345fa83b531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S (PERSON Johney/NNP) works/VBZ at/IN (ORGANIZATION Intel/NNP) ./.)\n"
          ]
        }
      ]
    }
  ]
}